{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow\n",
        "\n",
        "## Introduction\n",
        "\n",
        "### Basics"
      ],
      "metadata": {
        "id": "TUFX108Fy4_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  \n",
        "print(tf.__version__)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94V6DfWEzcvC",
        "outputId": "a9e704cd-6a40-4730-d0ca-b670ca64660d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors"
      ],
      "metadata": {
        "id": "Tvp9i6Sp1gK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = tf.random.normal([1,2,3])\n",
        "tensor2 = tf.reshape(tensor1, [2,3,1]) \n",
        "tensor3 = tf.reshape(tensor2, [3, -1])\n",
        "\n",
        "print(f\"Tensor 1 shape is {tensor1.shape}, so rank/degree {tensor1.ndim}\")\n",
        "print(f\"Tensor 2 shape is {tensor2.shape}\")\n",
        "print(f\"Tensor 3 shape is {tensor3.shape}\")\n",
        "\n",
        "print(tensor1)\n",
        "print(tensor2)\n",
        "print(tensor3)"
      ],
      "metadata": {
        "id": "-_jPEwQx0LBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235ca521-a25d-404b-b8ee-21ef3d4354ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1 shape is (1, 2, 3), so rank/degree 3\n",
            "Tensor 2 shape is (2, 3, 1)\n",
            "Tensor 3 shape is (3, 2)\n",
            "tf.Tensor(\n",
            "[[[-1.0778204  -0.04934228  0.17698595]\n",
            "  [ 0.8112834  -0.48283577  1.9005011 ]]], shape=(1, 2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-1.0778204 ]\n",
            "  [-0.04934228]\n",
            "  [ 0.17698595]]\n",
            "\n",
            " [[ 0.8112834 ]\n",
            "  [-0.48283577]\n",
            "  [ 1.9005011 ]]], shape=(2, 3, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-1.0778204  -0.04934228]\n",
            " [ 0.17698595  0.8112834 ]\n",
            " [-0.48283577  1.9005011 ]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subsetting\n",
        "matrix = [[1,2,3,4,5],\n",
        "          [6,7,8,9,10],\n",
        "          [11,12,13,14,15],\n",
        "          [16,17,18,19,20]]\n",
        "\n",
        "tensor = tf.Variable(matrix, dtype=tf.int32) \n",
        "print(f\"rank: {tf.rank(tensor)}, shape: {tensor.shape}\")\n",
        "\n",
        "print(f\"3rd element from row 1: {tensor[0,2]}\")\n",
        "print(f\"row 1: {tensor[0]}\")\n",
        "print(f\"column 1: {tensor[:, 0]}\")\n",
        "print(f\"row 2 and 4: {tensor[1::2]}\")\n",
        "print(f\"column 1 in row 2 and 3: {tensor[1:3,0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsKsT1VO4o9z",
        "outputId": "8a1ba5d6-4db4-495a-8404-0dd83cb76f35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank: 2, shape: (4, 5)\n",
            "3rd element from row 1: 3\n",
            "row 1: [1 2 3 4 5]\n",
            "column 1: [ 1  6 11 16]\n",
            "row 2 and 4: [[ 6  7  8  9 10]\n",
            " [16 17 18 19 20]]\n",
            "column 1 in row 2 and 3: [ 6 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic learning algorithms\n",
        "\n",
        "Here we use tf.Estimator, with production-ready models.\n",
        "\n",
        "Normally we would prototype with tf.keras using Sequential API, Functional API or Model Subclassing, then eventually convert to estimator.\n",
        "\n",
        "### Linear regression"
      ],
      "metadata": {
        "id": "M74xHVsH7kVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "PDgE8Odl7qxA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the titanic dataset\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') \n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') \n",
        "\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ],
      "metadata": {
        "id": "NRz0_v339axr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain.info()\n",
        "# dftrain.head()\n",
        "# dftrain.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN-5o5Fp_yk1",
        "outputId": "f6c5996b-3570-47bb-bdeb-8e5dd1ee9737"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   sex                 627 non-null    object \n",
            " 1   age                 627 non-null    float64\n",
            " 2   n_siblings_spouses  627 non-null    int64  \n",
            " 3   parch               627 non-null    int64  \n",
            " 4   fare                627 non-null    float64\n",
            " 5   class               627 non-null    object \n",
            " 6   deck                627 non-null    object \n",
            " 7   embark_town         627 non-null    object \n",
            " 8   alone               627 non-null    object \n",
            "dtypes: float64(2), int64(2), object(5)\n",
            "memory usage: 44.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']"
      ],
      "metadata": {
        "id": "kPO833sg_12H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature columns\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxvlGFuxFwI7",
        "outputId": "95546405-e8fc-4a70-d9cb-def4bbf62b51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input function: defines how the datasets is split into batches at each epoch\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  # return a function object for use\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "metadata": {
        "id": "I2EAfbUBGhYm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define, train and evaluate the model\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)  \n",
        "\n",
        "clear_output()\n",
        "for k, v in result.items():\n",
        "    print(f'{k:>20s}:\\t{v:4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKzQruDXId-C",
        "outputId": "89a57eaf-544c-4179-9214-7112bc91cd19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            accuracy:\t0.738636\n",
            "   accuracy_baseline:\t0.625000\n",
            "                 auc:\t0.835751\n",
            "auc_precision_recall:\t0.790810\n",
            "        average_loss:\t0.479295\n",
            "          label/mean:\t0.375000\n",
            "                loss:\t0.471968\n",
            "           precision:\t0.644231\n",
            "     prediction/mean:\t0.409639\n",
            "              recall:\t0.676768\n",
            "         global_step:\t200.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First dense neural network"
      ],
      "metadata": {
        "id": "gDMJ8HwULVXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the iris dataset\n",
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
      ],
      "metadata": {
        "id": "lQqpgmzqJNHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbef8e46-3abe-47fe-d1f5-062a3bba64ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "2194/2194 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "573/573 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()\n",
        "# train.head()\n",
        "# train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyUUG96dMduX",
        "outputId": "96e68ca8-8b47-4c75-d13f-8e198f5eea8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   SepalLength  120 non-null    float64\n",
            " 1   SepalWidth   120 non-null    float64\n",
            " 2   PetalLength  120 non-null    float64\n",
            " 3   PetalWidth   120 non-null    float64\n",
            " 4   Species      120 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')"
      ],
      "metadata": {
        "id": "HNbD9UTZMaqu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature columns\n",
        "feature_columns = []\n",
        "for key in train.keys():\n",
        "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMNvHAw9M0dl",
        "outputId": "ee1dc447-4c19-4f26-91b7-0e07f70b8532"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "KUA45ugzNOXV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[30, 10], # 2 hidden layers of 30 and 10 nodes\n",
        "    n_classes=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0fza0J_Nq86",
        "outputId": "ce1b87f6-9b67-4aae-8267-82b1a11ada52"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpte2vlzii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "    input_fn = lambda: input_fn(train, train_y, training=True), # we usa a lambda here\n",
        "    steps=5000)\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "nuFYyiIpOVVy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_YSrr_cPT7S",
        "outputId": "c3c89e59-af78-4f6a-91eb-aea51574c1c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set accuracy: 0.733\n",
            "\n"
          ]
        }
      ]
    }
  ]
}